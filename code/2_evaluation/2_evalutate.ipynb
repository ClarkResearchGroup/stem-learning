{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9wfbzq2k-a-J"
   },
   "source": [
    "Algorithm and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NdHmPh6EGSnU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "\n",
    "def convolve(num_convs, label_img, thresh=0.6):\n",
    "    kernel = np.ones((3,3))/9.\n",
    "    conv_label_img = (label_img - np.min(label_img))/np.ptp(label_img)\n",
    "    conv_label_img = np.array(conv_label_img >= thresh).astype(int)\n",
    "    for k in range(num_convs):\n",
    "        conv_label_img = convolve2d(conv_label_img, kernel, mode='same')\n",
    "        conv_label_img = np.array(conv_label_img >= thresh).astype(int)\n",
    "    return conv_label_img\n",
    "\n",
    "\n",
    "def get_center_list(conv_label_img, radius):\n",
    "    size_x, size_y = conv_label_img.shape\n",
    "    center_list = [[i, j] for i in range(size_x) for j in range(size_y)\\\n",
    "                  if conv_label_img[i,j]==1]\n",
    "\n",
    "    new_center_list = []\n",
    "    while len(center_list) > 0:\n",
    "        avg_list = []\n",
    "        i, j = center_list.pop(0)\n",
    "        avg_list.append([i, j])\n",
    "\n",
    "        for k in range(len(center_list)):\n",
    "            ik, jk = center_list.pop(0)\n",
    "            rsq = (i - ik)*(i - ik) + (j - jk)*(j - jk)\n",
    "            if rsq < radius*radius:\n",
    "                avg_list.append([ik, jk])\n",
    "            else:\n",
    "                center_list.append([ik, jk])\n",
    "\n",
    "        avg_list = zip(*avg_list)\n",
    "        i_new = int(round(np.mean(avg_list[0])))\n",
    "        j_new = int(round(np.mean(avg_list[1])))\n",
    "        new_center_list.append((i_new, j_new))\n",
    "\n",
    "    #print len(new_center_list), \"centers found\"\n",
    "    return new_center_list\n",
    "\n",
    "\n",
    "def detect_diff(label_center, evals_center, radius=7.5):\n",
    "    match_list = []\n",
    "    label_list = list(label_center)\n",
    "    evals_list = list(evals_center)\n",
    "    \n",
    "    for j in range(len(label_list)):\n",
    "        (lx, ly) = label_list.pop(0)\n",
    "        match_found = False\n",
    "        for k in range(len(evals_list)):\n",
    "            (ex, ey) = evals_list[k]\n",
    "            rsq = (lx - ex)*(lx - ex) + (ly - ey)*(ly - ey)\n",
    "            if rsq <= radius*radius:\n",
    "                evals_list.pop(k)\n",
    "                match_coord = ((lx + ex)/2, (ly + ey)/2)\n",
    "                match_list.append(match_coord)\n",
    "                match_found = True\n",
    "                break\n",
    "        if not match_found:\n",
    "            label_list.append((lx, ly))\n",
    "    return match_list, label_list, evals_list\n",
    "\n",
    "def calculate_accuracy(label_file_list, evals_file_list, num_convs):\n",
    "\n",
    "    label_img = process_label(label_file_list)[:,:,1]\n",
    "    evals_img = process_label(evals_file_list)[:,:,1]\n",
    "\n",
    "    conv_label_img = convolve(num_convs, label_img)\n",
    "    conv_evals_img = convolve(num_convs, evals_img)\n",
    "\n",
    "    conv_label_cen = get_center_list(conv_label_img, 7.5)\n",
    "    conv_evals_cen = get_center_list(conv_evals_img, 7.5)\n",
    "\n",
    "    match_list, label_list, evals_list = detect_diff(conv_label_cen, conv_evals_cen)\n",
    "    \n",
    "    TP = len(match_list)\n",
    "    FP = len(evals_list)\n",
    "    FN = len(label_list)\n",
    "    TN = 304*16 - TP - FP - FN\n",
    "\n",
    "    return TP ,FP, FN, TN\n",
    "\n",
    "def get_acc_list(lbl_list, num_images, num_convs, label_dir, predi_dir, image_dir):\n",
    "    acc_list = {}\n",
    "    for lbl in lbl_list:\n",
    "        acc_list[lbl] = []\n",
    "        print lbl\n",
    "        for i in range(num_images):\n",
    "            print \"\\t\", i\n",
    "            label_file_list = [label_dir + 'label_' + lbl + '/image' + str(i) + '_label' + lbl + '.tiff']\n",
    "            evals_file_list = [predi_dir + 'label_' + lbl + '/image' + str(i) + '_' + lbl + '_prediction.png']\n",
    "\n",
    "            TP ,FP, FN, TN = calculate_accuracy(label_file_list, evals_file_list, num_convs)\n",
    "\n",
    "            acc_list[lbl].append([TP, FP, FN, TN])\n",
    "\n",
    "        acc_list[lbl] = zip(*acc_list[lbl])\n",
    "    json.dump(acc_list, open(image_dir + \"acc_list.json\", 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "76E7IXGm-lPc"
   },
   "source": [
    "Imports and parameter initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mWDv4R-rd98k"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../preprocessing')\n",
    "from image_parse import *\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_KRVkRzACG1p"
   },
   "outputs": [],
   "source": [
    "parent_dir  = \"/content/drive/My Drive/stem-learning/\"\n",
    "image_dir = parent_dir + \"data/WSeTe/full_simulation_set/\"\n",
    "(label_dir, predi_dir) = [image_dir + 'label/', image_dir + 'prediction/']\n",
    "lbl_list = ['2Te', 'Se', 'TeSe', 'vacancy']\n",
    "num_convs = 2\n",
    "num_images = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CRATpgZU-pvd"
   },
   "source": [
    "Evaluate all the simulated images by looking at the centers in the predictions and labels and matching them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f00ez_1C_Gjl"
   },
   "outputs": [],
   "source": [
    "#get_acc_list(lbl_list, num_images, num_convs, label_dir, predi_dir, image_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yJcQlnvvFc96"
   },
   "source": [
    "Let's look more closely into how this process happens. \n",
    "First, Let's load a label and prediction image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ELeY7rDpFhOe"
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imsave\n",
    "i, lbl = 19, 'TeSe'\n",
    "label_file_list = [label_dir + 'label_' + lbl + '/image' + str(i) + '_label' + lbl + '.tiff']\n",
    "evals_file_list = [predi_dir + 'label_' + lbl + '/image' + str(i) + '_' + lbl + '_prediction.png']\n",
    "\n",
    "label_img = process_label(label_file_list)[:,:,1]\n",
    "evals_img = process_label(evals_file_list)[:,:,1]\n",
    "\n",
    "imsave(\"1_ex_label.png\", label_img)\n",
    "imsave(\"1_ex_evals.png\", evals_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2SL4633dK7YD"
   },
   "source": [
    "Next, let's get the centers of these defects. To do this, we first normalize the image so that the range of the pixels is $[0,1]$. Next, we convolve the image with the kernel \n",
    "\n",
    "$\\left(\\begin{matrix}1&1&1\\\\1&1&1\\\\1&1&1\\end{matrix}\\right)$\n",
    "\n",
    "Then we normalize again and threshold the pixels, setting values less than 0.6 to zero and values above 0.6 to 1. \n",
    "\n",
    "This process is done 2 times to decrease the size of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ATmfy4sQOb5R"
   },
   "outputs": [],
   "source": [
    "kernel = np.ones((3,3))/9.\n",
    "thresh = 0.6\n",
    "\n",
    "\n",
    "#label\n",
    "conv_label_img = (label_img - np.min(label_img))/np.ptp(label_img)\n",
    "conv_label_img = np.array(conv_label_img >= thresh).astype(int)\n",
    "\n",
    "#conv 1\n",
    "conv_label_img = convolve2d(conv_label_img, kernel, mode='same')\n",
    "imsave(\"2_ex_label_conv_11.png\", conv_label_img)\n",
    "conv_label_img = np.array(conv_label_img >= thresh).astype(int)\n",
    "imsave(\"2_ex_label_conv_12.png\", conv_label_img)\n",
    "\n",
    "#conv 2\n",
    "conv_label_img = convolve2d(conv_label_img, kernel, mode='same')\n",
    "imsave(\"2_ex_label_conv_21.png\", conv_label_img)\n",
    "conv_label_img = np.array(conv_label_img >= thresh).astype(int)\n",
    "imsave(\"2_ex_label_conv_22.png\", conv_label_img)\n",
    "\n",
    "\n",
    "#evals\n",
    "conv_evals_img = (evals_img - np.min(evals_img))/np.ptp(evals_img)\n",
    "conv_evals_img = np.array(conv_evals_img >= thresh).astype(int)\n",
    "\n",
    "#conv 1\n",
    "conv_evals_img = convolve2d(conv_evals_img, kernel, mode='same')\n",
    "imsave(\"2_ex_evals_conv_11.png\", conv_evals_img)\n",
    "conv_evals_img = np.array(conv_evals_img >= thresh).astype(int)\n",
    "imsave(\"2_ex_evals_conv_12.png\", conv_evals_img)\n",
    "\n",
    "#conv 2\n",
    "conv_evals_img = convolve2d(conv_evals_img, kernel, mode='same')\n",
    "imsave(\"2_ex_evals_conv_21.png\", conv_evals_img)\n",
    "conv_evals_img = np.array(conv_evals_img >= thresh).astype(int)\n",
    "imsave(\"2_ex_evals_conv_22.png\", conv_evals_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EaVeoMAiU64e"
   },
   "source": [
    "This process filters out any predictions that are not as confidently labeled. That is, the big dots are confident labels, while the small dots are not as confident.\n",
    "\n",
    "Next we find the centers of these defects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LAeqbeB9WLRX"
   },
   "outputs": [],
   "source": [
    "conv_label_cen = get_center_list(conv_label_img, 7.5)\n",
    "conv_evals_cen = get_center_list(conv_evals_img, 7.5)\n",
    "\n",
    "x_list, y_list = zip(*conv_label_cen)\n",
    "fig = plt.figure(frameon=False)\n",
    "fig.set_size_inches(20,20)\n",
    "ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "ax.set_axis_off()\n",
    "fig.add_axes(ax)\n",
    "ax.imshow(label_img, cmap='gray')\n",
    "ax.scatter(y_list, x_list, alpha = 0.5, color='y')\n",
    "ax.set_xlim(0,1024)\n",
    "ax.set_ylim(1024,0)\n",
    "plt.savefig(\"3_ex_label_centers.png\")\n",
    "plt.close()\n",
    "\n",
    "x_list, y_list = zip(*conv_evals_cen)\n",
    "fig = plt.figure(frameon=False)\n",
    "fig.set_size_inches(20,20)\n",
    "ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "ax.set_axis_off()\n",
    "fig.add_axes(ax)\n",
    "ax.imshow(evals_img, cmap='gray')\n",
    "ax.scatter(y_list, x_list, alpha = 0.5, color='y')\n",
    "ax.set_xlim(0,1024)\n",
    "ax.set_ylim(1024,0)\n",
    "plt.savefig(\"3_ex_evals_centers.png\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v6kozxr_iE2t"
   },
   "source": [
    "Next we compare the centers from the labels and the predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "AjS3NYhsiLiC",
    "outputId": "c6948f2d-04bb-45df-f2b5-29980ad8780d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True  Positives:   277         False Positives:   12\n",
      "True  Negatives:   4570         False Negatives:   5\n"
     ]
    }
   ],
   "source": [
    "match_list, label_list, evals_list = detect_diff(conv_label_cen, conv_evals_cen)\n",
    "\n",
    "TP = len(match_list)\n",
    "FN = len(label_list)\n",
    "FP = len(evals_list)\n",
    "TN = 304*16 - (TP + FN) - FP\n",
    "print \"True  Positives:   {}         False Positives:   {}\".format(TP, FP)\n",
    "print \"True  Negatives:   {}         False Negatives:   {}\".format(TN, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A2ZTrXyMjKFe"
   },
   "outputs": [],
   "source": [
    "[mx_list, my_list] = [[],[]] if TP == 0 else zip(*match_list)\n",
    "[lx_list, ly_list] = [[],[]] if FN == 0 else zip(*label_list)\n",
    "[ex_list, ey_list] = [[],[]] if FP == 0 else zip(*evals_list)\n",
    "\n",
    "fig = plt.figure(frameon=False)\n",
    "fig.set_size_inches(20,20)\n",
    "ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "ax.set_axis_off()\n",
    "fig.add_axes(ax)\n",
    "ax.imshow(np.zeros((1024, 1024)), cmap='gray')\n",
    "ax.scatter(my_list, mx_list, label='True Positive')\n",
    "ax.scatter(ly_list, lx_list, label='False Negative')\n",
    "ax.scatter(ey_list, ex_list, label='False Positive')\n",
    "ax.set_ylim(1024, 0)\n",
    "ax.set_xlim(0,1024)\n",
    "#ax.legend(loc='best')\n",
    "\n",
    "plt.savefig(\"4_ex_defect_results.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BDrPKt90EKSL",
    "outputId": "77d34a53-2bae-4e6a-96cc-4397fff4d772"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2Te\n",
      "\tTrain\n",
      "\t\trecall:                100.00%\n",
      "\t\tprecision:             100.00%\n",
      "\t\tF1 score:              100.00%\n",
      "\t\tbalanced accuracy:     100.00%\n",
      "\n",
      "\n",
      "\n",
      "\tTest\n",
      "\t\trecall:                99.60%\n",
      "\t\tprecision:             99.35%\n",
      "\t\tF1 score:              99.47%\n",
      "\t\tbalanced accuracy:     99.77%\n",
      "\n",
      "\n",
      "\n",
      "\tTrain and Test\n",
      "\t\trecall:                99.62%\n",
      "\t\tprecision:             99.39%\n",
      "\t\tF1 score:              99.51%\n",
      "\t\tbalanced accuracy:     99.79%\n",
      "Se\n",
      "\tTrain\n",
      "\t\trecall:                100.00%\n",
      "\t\tprecision:             100.00%\n",
      "\t\tF1 score:              100.00%\n",
      "\t\tbalanced accuracy:     100.00%\n",
      "\n",
      "\n",
      "\n",
      "\tTest\n",
      "\t\trecall:                99.56%\n",
      "\t\tprecision:             99.89%\n",
      "\t\tF1 score:              99.73%\n",
      "\t\tbalanced accuracy:     99.78%\n",
      "\n",
      "\n",
      "\n",
      "\tTrain and Test\n",
      "\t\trecall:                99.59%\n",
      "\t\tprecision:             99.90%\n",
      "\t\tF1 score:              99.74%\n",
      "\t\tbalanced accuracy:     99.79%\n",
      "TeSe\n",
      "\tTrain\n",
      "\t\trecall:                100.00%\n",
      "\t\tprecision:             100.00%\n",
      "\t\tF1 score:              100.00%\n",
      "\t\tbalanced accuracy:     100.00%\n",
      "\n",
      "\n",
      "\n",
      "\tTest\n",
      "\t\trecall:                97.82%\n",
      "\t\tprecision:             98.85%\n",
      "\t\tF1 score:              98.33%\n",
      "\t\tbalanced accuracy:     98.88%\n",
      "\n",
      "\n",
      "\n",
      "\tTrain and Test\n",
      "\t\trecall:                97.95%\n",
      "\t\tprecision:             98.92%\n",
      "\t\tF1 score:              98.43%\n",
      "\t\tbalanced accuracy:     98.94%\n",
      "vacancy\n",
      "\tTrain\n",
      "\t\trecall:                100.00%\n",
      "\t\tprecision:             100.00%\n",
      "\t\tF1 score:              100.00%\n",
      "\t\tbalanced accuracy:     100.00%\n",
      "\n",
      "\n",
      "\n",
      "\tTest\n",
      "\t\trecall:                99.82%\n",
      "\t\tprecision:             99.54%\n",
      "\t\tF1 score:              99.68%\n",
      "\t\tbalanced accuracy:     99.91%\n",
      "\n",
      "\n",
      "\n",
      "\tTrain and Test\n",
      "\t\trecall:                99.83%\n",
      "\t\tprecision:             99.57%\n",
      "\t\tF1 score:              99.70%\n",
      "\t\tbalanced accuracy:     99.91%\n"
     ]
    }
   ],
   "source": [
    "def fmt(arr):\n",
    "    return np.array((arr)).astype(np.float)\n",
    "\n",
    "def print_results(recall, precision, F1, bal_acc):\n",
    "    print \"\\t\\trecall:                {:0.2f}%\".format(recall*100)\n",
    "    print \"\\t\\tprecision:             {:0.2f}%\".format(precision*100)\n",
    "    print \"\\t\\tF1 score:              {:0.2f}%\".format(F1*100)\n",
    "    print \"\\t\\tbalanced accuracy:     {:0.2f}%\".format(bal_acc*100)\n",
    "    \n",
    "def get_results(TP, FP, FN, TN):\n",
    "    TNR = TN/(TN + FP)\n",
    "    TPR = TP/(TP + FN)\n",
    "    \n",
    "    recall    = TP/(TP + FN)\n",
    "    precision = TP/(TP + FP)\n",
    "    F1        = 2*recall*precision/(recall + precision)\n",
    "    bal_acc   = 0.5*(TNR + TPR)\n",
    "    return recall, precision, F1, bal_acc\n",
    "\n",
    "acc_list = json.load(open(image_dir + \"acc_list.json\", 'r'))\n",
    "import matplotlib.pyplot as plt\n",
    "for lbl in lbl_list:\n",
    "    TP_list, FP_list, FN_list, TN_list = map(fmt, acc_list[lbl])\n",
    "    \n",
    "    TP_train, FP_train, FN_train, TN_train = map(sum, [TP_list[:3], FP_list[:3], FN_list[:3], TN_list[:3]])\n",
    "    TP_test,  FP_test,  FN_test,  TN_test  = map(sum, [TP_list[3:], FP_list[3:], FN_list[3:], TN_list[3:]])\n",
    "    TP_both,  FP_both,  FN_both,  TN_both  = map(sum, [TP_list,     FP_list,     FN_list,     TN_list])\n",
    "\n",
    "    \n",
    "    print lbl\n",
    "    print \"\\tTrain\"\n",
    "    print_results(*get_results(TP_train, FP_train, FN_train, TN_train))\n",
    "    print \"\\n\\n\"\n",
    "    \n",
    "    print \"\\tTest\"\n",
    "    print_results(*get_results(TP_test, FP_test, FN_test, TN_test))\n",
    "    print \"\\n\\n\"\n",
    "    \n",
    "    print \"\\tTrain and Test\"\n",
    "    print_results(*get_results(TP_both, FP_both, FN_both, TN_both))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mKoqLKcXh0ub"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "accuracy.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
