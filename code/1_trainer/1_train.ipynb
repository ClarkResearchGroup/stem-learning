{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script performs the training of a network after the dataset has been constructed. Three modules are used in this training:\n",
    "\n",
    "1. **input_data**: This module loads in the training data that was created, and prepares it so that it can be fed into the neural network for training.\n",
    "2. **models**: this module contains different types of neural network architectures. One can choose a model from this script and train it.\n",
    "3. **training_utilities**: this module contains functions to construct models, set up diagnostic files, and perform the training on the model.\n",
    "\n",
    "First, we import these modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from input_data import *\n",
    "from models import *\n",
    "from training_utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to provide parameter information based on the data and model we're using.\n",
    "\n",
    "**parent_dir**: This is the path to the \"stem-learning\" code\n",
    "\n",
    "**data_dir**: This is the path to the data that we created in the preprocessing section\n",
    "\n",
    "**sess_name**: we will create a folder in the \"results\" directory called session_name, where all the output will be stored\n",
    "\n",
    "**N**: This is the pixel width/height of the input images (note we're assuming a square image)\n",
    "\n",
    "**k_fac**: this is a factor that describes how many channels we want per layer in our FCNs. Whatever the default value is per layer, it is multiplied by k_fac.\n",
    "\n",
    "**nb_classes**: this is the number of labels that we are learning at once. For example, if our data is just the \"2Te\" labels, then nb_classes = 2 (2Te and no defect). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = '/home/abid/Dropbox/Research/Clarksearch/stem/stem-learning/'\n",
    "data_dir   = parent_dir + 'data/WSeTe/simulated/parsed_label_2Te/'\n",
    "sess_name  = '2Te'\n",
    "N          = 256\n",
    "k_fac      = 16\n",
    "nb_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables below are then created to locate the directories that we'll be storing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import makedirs\n",
    "sess_dir = parent_dir + \"results/\" + sess_name + \"/\"\n",
    "makedirs(sess_dir, exist_ok=True)\n",
    "\n",
    "model_weights_fn = sess_dir + \"weights.h5\"\n",
    "model_fn         = sess_dir + \"model.json\"\n",
    "diagnostics_fn   = sess_dir + \"diagnostics.dat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the model and set up a diagnostics file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0106 16:48:51.992354 140297698061184 deprecation_wrapper.py:119] From /home/abid/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0106 16:48:52.001519 140297698061184 deprecation_wrapper.py:119] From /home/abid/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0106 16:48:52.003815 140297698061184 deprecation_wrapper.py:119] From /home/abid/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0106 16:48:52.025401 140297698061184 deprecation_wrapper.py:119] From /home/abid/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0106 16:48:52.026273 140297698061184 deprecation_wrapper.py:119] From /home/abid/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0106 16:48:52.070010 140297698061184 deprecation_wrapper.py:119] From /home/abid/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0106 16:48:52.179932 140297698061184 deprecation_wrapper.py:119] From /home/abid/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0106 16:48:52.244206 140297698061184 deprecation.py:506] From /home/abid/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0106 16:48:54.248574 140297698061184 deprecation_wrapper.py:119] From /home/abid/.local/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = construct_model(N, k_fac, nb_classes, sess_dir, model_fn, model_weights_fn)\n",
    "step = setup_diagnostics(diagnostics_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training step: 0\ttraining file: train_2.p\n",
      "\tgrabbing data\n",
      "\tdone\n",
      "\tcalculating accuracy\n",
      "118\n",
      "191\n",
      "2294\n",
      "182\n",
      "1578\n",
      "214\n",
      "1310\n",
      "216\n",
      "959\n",
      "225\n",
      "1787\n",
      "230\n",
      "1391\n",
      "261\n",
      "846\n",
      "240\n",
      "1203\n",
      "250\n",
      "878\n",
      "256\n",
      "1533\n",
      "134\n",
      "1442\n",
      "177\n",
      "1232\n",
      "198\n",
      "1430\n",
      "248\n",
      "1069\n",
      "284\n",
      "911\n",
      "271\n",
      "1616\n",
      "216\n",
      "1502\n",
      "214\n",
      "1237\n",
      "196\n",
      "1296\n",
      "240\n",
      "1089\n",
      "164\n",
      "771\n",
      "177\n",
      "985\n",
      "211\n",
      "1620\n",
      "250\n",
      "982\n",
      "198\n",
      "786\n",
      "177\n",
      "1419\n",
      "244\n",
      "1214\n",
      "261\n",
      "1100\n",
      "175\n",
      "1637\n",
      "141\n",
      "1037\n",
      "208\n",
      "1077\n",
      "282\n",
      "978\n",
      "134\n",
      "901\n",
      "260\n",
      "1314\n",
      "177\n",
      "1377\n",
      "177\n",
      "1780\n",
      "196\n",
      "1287\n",
      "196\n",
      "1747\n",
      "182\n",
      "1033\n",
      "194\n",
      "1033\n",
      "241\n",
      "1547\n",
      "151\n",
      "3050\n",
      "201\n",
      "1228\n",
      "198\n",
      "1733\n",
      "248\n",
      "1843\n",
      "216\n",
      "1955\n",
      "240\n",
      "1272\n",
      "167\n",
      "2019\n",
      "167\n",
      "1025\n",
      "182\n",
      "1240\n",
      "208\n",
      "868\n",
      "214\n",
      "817\n",
      "271\n",
      "1498\n",
      "208\n",
      "1646\n",
      "151\n",
      "1254\n",
      "202\n",
      "1089\n",
      "213\n",
      "1420\n",
      "197\n",
      "1896\n",
      "282\n",
      "921\n",
      "191\n",
      "1456\n",
      "197\n",
      "2481\n",
      "160\n",
      "1441\n",
      "182\n",
      "935\n",
      "282\n",
      "1338\n",
      "175\n",
      "1932\n",
      "185\n",
      "2320\n",
      "282\n",
      "1635\n",
      "214\n",
      "1775\n",
      "151\n",
      "2011\n",
      "179\n",
      "1155\n",
      "151\n",
      "2923\n",
      "216\n",
      "1240\n",
      "240\n",
      "914\n",
      "151\n",
      "2522\n",
      "216\n",
      "950\n",
      "141\n",
      "970\n",
      "261\n",
      "1102\n",
      "177\n",
      "2018\n",
      "208\n",
      "1548\n",
      "260\n",
      "933\n",
      "261\n",
      "1492\n",
      "177\n",
      "1909\n",
      "194\n",
      "903\n",
      "208\n",
      "1749\n",
      "194\n",
      "946\n",
      "177\n",
      "2769\n",
      "141\n",
      "1323\n",
      "151\n",
      "1811\n",
      "261\n",
      "1233\n",
      "248\n",
      "1022\n",
      "297\n",
      "1443\n",
      "208\n",
      "1412\n",
      "261\n",
      "945\n",
      "282\n",
      "1506\n",
      "164\n",
      "982\n",
      "201\n",
      "1273\n",
      "225\n",
      "1510\n",
      "151\n",
      "1689\n",
      "151\n",
      "1056\n",
      "198\n",
      "1576\n",
      "271\n",
      "1886\n",
      "185\n",
      "1735\n",
      "172\n",
      "3030\n",
      "134\n",
      "1381\n",
      "297\n",
      "1302\n",
      "172\n",
      "2338\n",
      "282\n",
      "1298\n",
      "198\n",
      "2578\n",
      "201\n",
      "1050\n",
      "179\n",
      "2224\n",
      "196\n",
      "1795\n",
      "208\n",
      "1060\n",
      "194\n",
      "787\n",
      "198\n",
      "1192\n",
      "297\n",
      "1440\n",
      "177\n",
      "1372\n",
      "177\n",
      "1644\n",
      "297\n",
      "1448\n",
      "\tdone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0106 16:49:31.480357 140297698061184 deprecation.py:323] From /home/abid/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1058 samples, validate on 118 samples\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "train(step, data_dir, N, nb_classes, model, diagnostics_fn, model_weights_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
