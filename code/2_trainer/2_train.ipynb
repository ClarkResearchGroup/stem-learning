{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training FCN Model\n",
    "This script performs the training of a network after the dataset has been constructed. Four modules are used in this training:\n",
    "\n",
    "1. `input_data.py`: This module loads in the training and testing data that was created, and prepares it so that it can be fed into the neural network for training.\n",
    "2. `models.py`: this module contains different types of neural network architectures. One can choose a model from this script and train it.\n",
    "3. `training_utilities.py`: this module contains functions to construct models, set up diagnostic files, and perform the training on the model.\n",
    "4. `accuracy.py`: The accuracy that the FCN outputs looks at the predicted label and evaluated label, and does a pixelwise comparison (#pixels set to the correct value)/(#pixels in the image). This isn't the best way to determine the success of our model. Rather, we want to look at a metric that shows that the model is detecting defects (where each defect consists of multiple pixels). Hence we use measures such as the recall, which is the number of true positive defect detections TN over the true positives plus the false negatives (FN), R = TN/(TN+FN). This module helps in calculating such metrics\n",
    "\n",
    "First, we import these modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from input_data import *\n",
    "from models import *\n",
    "from training_utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters ##\n",
    "Next, we need to provide parameter information based on the data and model we're using.\n",
    "\n",
    "**parent_dir**: This is the path to the \"stem-learning\" code\n",
    "\n",
    "**data_dir**: This is the path to the data that we created in the preprocessing section\n",
    "\n",
    "**sess_name**: we will create a folder in the \"results\" directory called session_name, where all the output will be stored\n",
    "\n",
    "**N**: This is the pixel width/height of the input images (note we're assuming a square image)\n",
    "\n",
    "**k_fac**: this is a factor that describes how many channels we want per layer in our FCNs. Whatever the default value is per layer, it is multiplied by k_fac.\n",
    "\n",
    "**nb_classes**: this is the number of labels that we are learning at once. For example, if our data is just the \"2Te\" labels, then nb_classes = 2 (2Te and no defect). \n",
    "\n",
    "**dropout**: This is the dropout rate at the end of our FCN\n",
    "\n",
    "**num_steps**: The total number of steps to train on (-1 for infinite loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = 'C:/Users/abidk/Dropbox/Development/programs/stem-learning/'\n",
    "data_dir   = parent_dir + 'data/WSe/sim_50_gan/parsed_label_1vacancy/'\n",
    "sess_name  = '1vacancy'\n",
    "N          = 256\n",
    "k_fac      = 16\n",
    "nb_classes = 2\n",
    "num_steps  = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables below are then created to locate the directories that we'll be storing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import makedirs\n",
    "sess_dir = parent_dir + \"results/\" + sess_name + \"/\"\n",
    "makedirs(sess_dir, exist_ok=True)\n",
    "\n",
    "model_weights_fn = sess_dir + \"weights.h5\"\n",
    "model_fn         = sess_dir + \"model.json\"\n",
    "diagnostics_fn   = sess_dir + \"diagnostics.dat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the model and set up a diagnostics file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights\n",
      "continuing session with step79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abidk\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "model = construct_model(N, k_fac, nb_classes, sess_dir, model_fn, model_weights_fn)\n",
    "step = setup_diagnostics(diagnostics_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training step: 79\ttraining file: train_00124.p\n",
      "\tgrabbing data\n",
      "\tdone\n",
      "32/32 - 13s - loss: -7.1894e+01 - accuracy: 0.9954 - val_loss: -5.8897e+01 - val_accuracy: 0.9960\n",
      "\tcalculating accuracy\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abidk\\Dropbox\\Development\\programs\\stem-learning\\code\\2_trainer\\accuracy.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  conv_label_img = (label_img - np.min(label_img))/np.ptp(label_img)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tdone\n",
      "TP = 0, FP = 0, FN = 16253, TN = 497507\n",
      "recall = 0.0, precision = -1, F1 = -1, bal_acc = 0.5\n",
      "training step: 80\ttraining file: train_00033.p\n",
      "\tgrabbing data\n",
      "\tdone\n",
      "32/32 - 7s - loss: -7.2813e+01 - accuracy: 0.9942 - val_loss: -7.8962e+01 - val_accuracy: 0.9960\n",
      "\tcalculating accuracy\n",
      "0.0\n",
      "\tdone\n",
      "TP = 0, FP = 0, FN = 16253, TN = 497507\n",
      "recall = 0.0, precision = -1, F1 = -1, bal_acc = 0.5\n",
      "training step: 81\ttraining file: train_00086.p\n",
      "\tgrabbing data\n",
      "\tdone\n",
      "32/32 - 7s - loss: -7.4123e+01 - accuracy: 0.9965 - val_loss: -8.6290e+01 - val_accuracy: 0.9960\n",
      "\tcalculating accuracy\n",
      "0.0\n",
      "\tdone\n",
      "TP = 0, FP = 0, FN = 16253, TN = 497507\n",
      "recall = 0.0, precision = -1, F1 = -1, bal_acc = 0.5\n",
      "training step: 82\ttraining file: train_00084.p\n",
      "\tgrabbing data\n",
      "\tdone\n",
      "32/32 - 7s - loss: -7.5224e+01 - accuracy: 0.9953 - val_loss: -8.8938e+01 - val_accuracy: 0.9960\n",
      "\tcalculating accuracy\n",
      "0.0\n",
      "\tdone\n",
      "TP = 0, FP = 0, FN = 16253, TN = 497507\n",
      "recall = 0.0, precision = -1, F1 = -1, bal_acc = 0.5\n",
      "training step: 83\ttraining file: train_00044.p\n",
      "\tgrabbing data\n",
      "\tdone\n",
      "32/32 - 7s - loss: -7.6018e+01 - accuracy: 0.9947 - val_loss: -9.0944e+01 - val_accuracy: 0.9960\n",
      "\tcalculating accuracy\n",
      "0.0\n",
      "\tdone\n",
      "TP = 0, FP = 0, FN = 16253, TN = 497507\n",
      "recall = 0.0, precision = -1, F1 = -1, bal_acc = 0.5\n",
      "training step: 84\ttraining file: train_00154.p\n",
      "\tgrabbing data\n",
      "\tdone\n",
      "32/32 - 7s - loss: -7.7305e+01 - accuracy: 0.9951 - val_loss: -9.2678e+01 - val_accuracy: 0.9960\n",
      "\tcalculating accuracy\n",
      "0.0\n",
      "\tdone\n",
      "TP = 0, FP = 0, FN = 16253, TN = 497507\n",
      "recall = 0.0, precision = -1, F1 = -1, bal_acc = 0.5\n",
      "training step: 85\ttraining file: train_00104.p\n",
      "\tgrabbing data\n",
      "\tdone\n",
      "32/32 - 7s - loss: -7.8496e+01 - accuracy: 0.9960 - val_loss: -9.4297e+01 - val_accuracy: 0.9960\n",
      "\tcalculating accuracy\n",
      "0.0\n",
      "\tdone\n",
      "TP = 0, FP = 0, FN = 16253, TN = 497507\n",
      "recall = 0.0, precision = -1, F1 = -1, bal_acc = 0.5\n",
      "training step: 86\ttraining file: train_00116.p\n",
      "\tgrabbing data\n",
      "\tdone\n",
      "32/32 - 7s - loss: -7.9037e+01 - accuracy: 0.9954 - val_loss: -9.3987e+01 - val_accuracy: 0.9960\n",
      "\tcalculating accuracy\n",
      "0.0\n",
      "\tdone\n",
      "TP = 0, FP = 0, FN = 16253, TN = 497507\n",
      "recall = 0.0, precision = -1, F1 = -1, bal_acc = 0.5\n",
      "training step: 87\ttraining file: train_00113.p\n",
      "\tgrabbing data\n",
      "\tdone\n",
      "32/32 - 7s - loss: -7.9744e+01 - accuracy: 0.9958 - val_loss: -9.4288e+01 - val_accuracy: 0.9960\n",
      "\tcalculating accuracy\n",
      "0.0\n",
      "\tdone\n",
      "TP = 0, FP = 0, FN = 16253, TN = 497507\n",
      "recall = 0.0, precision = -1, F1 = -1, bal_acc = 0.5\n",
      "training step: 88\ttraining file: train_00021.p\n",
      "\tgrabbing data\n",
      "\tdone\n",
      "32/32 - 7s - loss: -8.1110e+01 - accuracy: 0.9952 - val_loss: -9.6441e+01 - val_accuracy: 0.9960\n",
      "\tcalculating accuracy\n",
      "0.0\n",
      "\tdone\n",
      "TP = 0, FP = 0, FN = 16253, TN = 497507\n",
      "recall = 0.0, precision = -1, F1 = -1, bal_acc = 0.5\n",
      "training step: 89\ttraining file: train_00019.p\n",
      "\tgrabbing data\n",
      "\tdone\n",
      "32/32 - 7s - loss: -8.2223e+01 - accuracy: 0.9963 - val_loss: -9.1752e+01 - val_accuracy: 0.9960\n",
      "\tcalculating accuracy\n",
      "0.0\n",
      "\tdone\n",
      "TP = 0, FP = 0, FN = 16253, TN = 497507\n",
      "recall = 0.0, precision = -1, F1 = -1, bal_acc = 0.5\n",
      "training step: 90\ttraining file: train_00049.p\n",
      "\tgrabbing data\n",
      "\tdone\n",
      "32/32 - 7s - loss: -8.3073e+01 - accuracy: 0.9947 - val_loss: -8.2943e+01 - val_accuracy: 0.9960\n",
      "\tcalculating accuracy\n",
      "0.0\n",
      "\tdone\n",
      "TP = 0, FP = 0, FN = 16253, TN = 497507\n",
      "recall = 0.0, precision = -1, F1 = -1, bal_acc = 0.5\n",
      "training step: 91\ttraining file: train_00096.p\n",
      "\tgrabbing data\n",
      "\tdone\n",
      "32/32 - 7s - loss: -8.4081e+01 - accuracy: 0.9961 - val_loss: -8.5827e+01 - val_accuracy: 0.9960\n",
      "\tcalculating accuracy\n",
      "0.0\n",
      "\tdone\n",
      "TP = 0, FP = 0, FN = 16253, TN = 497507\n",
      "recall = 0.0, precision = -1, F1 = -1, bal_acc = 0.5\n",
      "training step: 92\ttraining file: train_00004.p\n",
      "\tgrabbing data\n",
      "\tdone\n",
      "32/32 - 7s - loss: -8.5354e+01 - accuracy: 0.9965 - val_loss: -9.3718e+01 - val_accuracy: 0.9960\n",
      "\tcalculating accuracy\n",
      "0.0\n",
      "\tdone\n",
      "TP = 0, FP = 0, FN = 16253, TN = 497507\n",
      "recall = 0.0, precision = -1, F1 = -1, bal_acc = 0.5\n",
      "training step: 93\ttraining file: train_00140.p\n",
      "\tgrabbing data\n",
      "\tdone\n",
      "32/32 - 7s - loss: -8.6721e+01 - accuracy: 0.9965 - val_loss: -1.0492e+02 - val_accuracy: 0.9960\n",
      "\tcalculating accuracy\n",
      "0.0\n",
      "\tdone\n",
      "TP = 0, FP = 0, FN = 16253, TN = 497507\n",
      "recall = 0.0, precision = -1, F1 = -1, bal_acc = 0.5\n",
      "training step: 94\ttraining file: train_00076.p\n",
      "\tgrabbing data\n",
      "\tdone\n",
      "32/32 - 7s - loss: -8.7452e+01 - accuracy: 0.9951 - val_loss: -1.0549e+02 - val_accuracy: 0.9960\n",
      "\tcalculating accuracy\n",
      "0.0\n",
      "\tdone\n",
      "TP = 0, FP = 0, FN = 16253, TN = 497507\n",
      "recall = 0.0, precision = -1, F1 = -1, bal_acc = 0.5\n",
      "training step: 95\ttraining file: train_00072.p\n",
      "\tgrabbing data\n",
      "\tdone\n",
      "32/32 - 7s - loss: -8.7787e+01 - accuracy: 0.9950 - val_loss: -1.0642e+02 - val_accuracy: 0.9960\n",
      "\tcalculating accuracy\n",
      "0.0\n",
      "\tdone\n",
      "TP = 0, FP = 0, FN = 16253, TN = 497507\n",
      "recall = 0.0, precision = -1, F1 = -1, bal_acc = 0.5\n",
      "training step: 96\ttraining file: train_00120.p\n",
      "\tgrabbing data\n",
      "\tdone\n",
      "32/32 - 7s - loss: -8.7832e+01 - accuracy: 0.9955 - val_loss: -1.0517e+02 - val_accuracy: 0.9960\n",
      "\tcalculating accuracy\n",
      "0.0\n",
      "\tdone\n",
      "TP = 0, FP = 0, FN = 16253, TN = 497507\n",
      "recall = 0.0, precision = -1, F1 = -1, bal_acc = 0.5\n",
      "training step: 97\ttraining file: train_00106.p\n",
      "\tgrabbing data\n",
      "\tdone\n",
      "32/32 - 7s - loss: -8.8230e+01 - accuracy: 0.9958 - val_loss: -1.0490e+02 - val_accuracy: 0.9960\n",
      "\tcalculating accuracy\n",
      "0.0\n",
      "\tdone\n",
      "TP = 0, FP = 0, FN = 16253, TN = 497507\n",
      "recall = 0.0, precision = -1, F1 = -1, bal_acc = 0.5\n",
      "training step: 98\ttraining file: train_00097.p\n",
      "\tgrabbing data\n",
      "\tdone\n",
      "32/32 - 7s - loss: -8.9545e+01 - accuracy: 0.9962 - val_loss: -1.0316e+02 - val_accuracy: 0.9960\n",
      "\tcalculating accuracy\n",
      "0.0\n",
      "\tdone\n",
      "TP = 0, FP = 0, FN = 16253, TN = 497507\n",
      "recall = 0.0, precision = -1, F1 = -1, bal_acc = 0.5\n",
      "training step: 99\ttraining file: train_00086.p\n",
      "\tgrabbing data\n",
      "\tdone\n",
      "32/32 - 7s - loss: -9.1213e+01 - accuracy: 0.9965 - val_loss: -1.0480e+02 - val_accuracy: 0.9960\n",
      "\tcalculating accuracy\n",
      "0.0\n",
      "\tdone\n",
      "TP = 0, FP = 0, FN = 16253, TN = 497507\n",
      "recall = 0.0, precision = -1, F1 = -1, bal_acc = 0.5\n",
      "training step: 100\ttraining file: train_00024.p\n",
      "\tgrabbing data\n",
      "\tdone\n",
      "32/32 - 7s - loss: -9.2783e+01 - accuracy: 0.9951 - val_loss: -9.4425e+01 - val_accuracy: 0.9960\n",
      "\tcalculating accuracy\n",
      "0.0\n",
      "\tdone\n",
      "TP = 0, FP = 0, FN = 16253, TN = 497507\n",
      "recall = 0.0, precision = -1, F1 = -1, bal_acc = 0.5\n",
      "training step: 101\ttraining file: train_00091.p\n",
      "\tgrabbing data\n",
      "\tdone\n",
      "32/32 - 7s - loss: -9.3765e+01 - accuracy: 0.9959 - val_loss: -4.7862e+01 - val_accuracy: 0.9960\n",
      "\tcalculating accuracy\n",
      "0.0\n",
      "\tdone\n",
      "TP = 0, FP = 0, FN = 16253, TN = 497507\n",
      "recall = 0.0, precision = -1, F1 = -1, bal_acc = 0.5\n",
      "training step: 102\ttraining file: train_00027.p\n",
      "\tgrabbing data\n",
      "\tdone\n",
      "32/32 - 10s - loss: -9.3808e+01 - accuracy: 0.9951 - val_loss: -7.6227e+01 - val_accuracy: 0.9960\n",
      "\tcalculating accuracy\n",
      "0.0\n",
      "\tdone\n",
      "TP = 0, FP = 0, FN = 16253, TN = 497507\n",
      "recall = 0.0, precision = -1, F1 = -1, bal_acc = 0.5\n",
      "training step: 103\ttraining file: train_00098.p\n",
      "\tgrabbing data\n",
      "\tdone\n",
      "32/32 - 8s - loss: -9.3968e+01 - accuracy: 0.9963 - val_loss: -6.2291e+01 - val_accuracy: 0.9960\n",
      "\tcalculating accuracy\n",
      "0.0\n",
      "\tdone\n",
      "TP = 0, FP = 0, FN = 16253, TN = 497507\n",
      "recall = 0.0, precision = -1, F1 = -1, bal_acc = 0.5\n",
      "training step: 104\ttraining file: train_00071.p\n",
      "\tgrabbing data\n",
      "\tdone\n",
      "32/32 - 10s - loss: -9.4416e+01 - accuracy: 0.9950 - val_loss: -1.1100e+02 - val_accuracy: 0.9960\n",
      "\tcalculating accuracy\n",
      "0.0\n",
      "\tdone\n",
      "TP = 0, FP = 0, FN = 16253, TN = 497507\n",
      "recall = 0.0, precision = -1, F1 = -1, bal_acc = 0.5\n",
      "training step: 105\ttraining file: train_00110.p\n",
      "\tgrabbing data\n",
      "\tdone\n",
      "32/32 - 8s - loss: -9.5096e+01 - accuracy: 0.9960 - val_loss: -9.9491e+01 - val_accuracy: 0.9960\n",
      "\tcalculating accuracy\n",
      "0.0\n",
      "\tdone\n",
      "TP = 0, FP = 0, FN = 16253, TN = 497507\n",
      "recall = 0.0, precision = -1, F1 = -1, bal_acc = 0.5\n",
      "training step: 106\ttraining file: train_00150.p\n",
      "\tgrabbing data\n",
      "\tdone\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[32,16,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/batch_normalization_29/FusedBatchNormV3 (defined at \\Dropbox\\Development\\programs\\stem-learning\\code\\2_trainer\\training_utilities.py:121) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_7866]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5188/2518137032.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiagnostics_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_weights_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Dropbox\\Development\\programs\\stem-learning\\code\\2_trainer\\training_utilities.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(step, data_dir, N, nb_classes, model, diagnostics_fn, model_weights_fn, num_steps, plots)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[1;31m# train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         history, TP, FP, FN, TN, recall, precision, F1, bal_acc = train_step(model, train_stem,\n\u001b[0m\u001b[0;32m    157\u001b[0m                 test_stem, model_weights_fn, plots)\n\u001b[0;32m    158\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TP = {}, FP = {}, FN = {}, TN = {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\Development\\programs\\stem-learning\\code\\2_trainer\\training_utilities.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(model, train_stem, test_stem, model_weights_fn, plots, epochs, batch_size)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m     history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\\\n\u001b[0m\u001b[0;32m    122\u001b[0m             validation_data=(x_test, y_test), verbose=2)\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[32,16,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/batch_normalization_29/FusedBatchNormV3 (defined at \\Dropbox\\Development\\programs\\stem-learning\\code\\2_trainer\\training_utilities.py:121) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_7866]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "train(step, data_dir, N, nb_classes, model, diagnostics_fn, model_weights_fn, num_steps=num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f914bd1de16c1cf64603350c7875757b86e1be9b95a8f8e4031868a367954dd5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
